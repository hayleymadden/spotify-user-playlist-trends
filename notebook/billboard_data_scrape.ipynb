{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d694d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "To source Billboard data for capstone, weekly charts need to be scraped from 1/1/2010 - 12/31/2017.\n",
    "example of first url: https://www.billboard.com/charts/hot-100/2010-01-09/\n",
    "\n",
    "To do: \n",
    "1: create list of dates \n",
    "2: create list of URLs\n",
    "3: develop scrape for one page\n",
    "4: apply loop for all URLs in list (use .append so all data loads into a dataframe.  add a column with a \"week of\" identifier.\n",
    "\n",
    "Charts are for the week prior: \n",
    "\n",
    "The Billboard Hot 100 is the music industry standard record chart in the United States for songs, published weekly by Billboard magazine. Chart rankings are based on sales (physical and digital), online streaming, and radio airplay in the U.S.[1]\n",
    "\n",
    "A new chart is compiled and released online to the public by Billboard's website on Tuesdays but post-dated to the following Saturday, when the printed magazine first reaches newsstands.[2] The weekly tracking period for sales is currently Friday–Thursday, after being changed in July 2015. It was initially Monday–Sunday when Nielsen started tracking sales in 1991. This tracking period also applies to compiling online streaming data. Radio airplay is readily available on a real-time basis, unlike sales figures and streaming, but is also tracked on the same Friday–Thursday cycle, effective with the chart dated July 17, 2021.[3] Previously, radio was tracked Monday–Sunday and, before July 2015, Wednesday–Tuesday.[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2faa7d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a78aa04",
   "metadata": {},
   "source": [
    "### Procure URLs for the Established Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4a4e8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#url string for hot 100 chart; date is the suffix following the string below\n",
    "base = 'https://www.billboard.com/charts/hot-100/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd430469",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function - creates a date string for every 7 days from start date\n",
    "def daterange(start_date, end_date):\n",
    "    for n in range(0, int((end_date - start_date).days) +1, 7):\n",
    "        yield start_date + timedelta(n)\n",
    "\n",
    "#initiation - list\n",
    "URL_list=[]\n",
    "\n",
    "# intitiation - parameters\n",
    "start = date(2010,1,9)\n",
    "end = date(2017,12,30)\n",
    "\n",
    "# append loop\n",
    "for dt in daterange(start, end):\n",
    "#    print(str(dt.strftime('%Y-%m-%d')))\n",
    "     URL_list.append(base + str(dt.strftime('%Y-%m-%d')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85f52547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "417"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(URL_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c492e26c",
   "metadata": {},
   "source": [
    "### Test URL; pull in first chart to query the page and build code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11570594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test URL\n",
    "# URL = 'https://www.billboard.com/charts/hot-100/2010-01-09'\n",
    "# response = requests.get(URL)\n",
    "# soup = BS(response.text)\n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadd3b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## intiialize dataframe\n",
    "billboard_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82e4381",
   "metadata": {},
   "outputs": [],
   "source": [
    "## establish for loop for URLs\n",
    "for URL in URL_list:\n",
    "    response = requests.get(URL)\n",
    "    soup = BS(response.text)\n",
    "    \n",
    "    week_date = str(URL[-10:])\n",
    "    \n",
    "    week_of = []\n",
    "    rank_current_week = []\n",
    "    title = []\n",
    "    artist = []\n",
    "    rank_prior_week = []\n",
    "    peak_pos = []\n",
    "    weeks_on_chart = []\n",
    "\n",
    "    content = soup.find_all(\"ul\", attrs={\"class\":\"o-chart-results-list-row\"})\n",
    "    for x in content:\n",
    "        data_points = []\n",
    "        song_title = x.select_one(\"h3\").get_text().strip()\n",
    "        chart_data = x.find_all(\"span\")\n",
    "        for point in chart_data:\n",
    "            if point(text=re.compile('NEW')):\n",
    "                chart_data.remove(point)\n",
    "            elif point(text=re.compile('RE-\\nENTRY')):\n",
    "                chart_data.remove(point)\n",
    "            else:\n",
    "                point = point.get_text().strip()\n",
    "                data_points.append(point)\n",
    "        week_of.append(week_date)\n",
    "        rank_current_week.append(data_points[0])\n",
    "        title.append(song_title)\n",
    "        artist.append(data_points[1])\n",
    "        rank_prior_week.append(data_points[2])\n",
    "        peak_pos.append(data_points[3])\n",
    "        weeks_on_chart.append(data_points[4])\n",
    "    \n",
    "    chart_dict = ({\n",
    "        'week_of':week_of, \n",
    "        'rank_current_week':rank_current_week, \n",
    "        'title':title, 'artist':artist, \n",
    "        'rank_prior_week':rank_prior_week, \n",
    "        'peak_pos':peak_pos, \n",
    "        'weeks_on_chart':weeks_on_chart})\n",
    "    \n",
    "    chart = pd.DataFrame(chart_dict)\n",
    "    billboard_data = pd.concat([billboard_data, chart])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a167cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4528e35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard_data.to_csv('../data/Billboard/billboard_chart_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b024cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE PAGE WORKING - DO NOT CHANGE\n",
    "# week_date = str(URL[-11:-1])\n",
    "\n",
    "# week_of = []\n",
    "# rank_current_week = []\n",
    "# title = []\n",
    "# artist = []\n",
    "# rank_prior_week = []\n",
    "# peak_pos = []\n",
    "# weeks_on_chart = []\n",
    "\n",
    "# content = soup.find_all(\"ul\", attrs={\"class\":\"o-chart-results-list-row\"})\n",
    "# for x in content:\n",
    "#     data_points = []\n",
    "#     song_title = x.select_one(\"h3\").get_text().strip()\n",
    "#     chart_data = x.find_all(\"span\")\n",
    "#     for point in chart_data:\n",
    "#         if point(text=re.compile('NEW')):\n",
    "#             chart_data.remove(point)\n",
    "#         elif point(text=re.compile('RE-\\nENTRY')):\n",
    "#             chart_data.remove(point)\n",
    "#         else:\n",
    "#             point = point.get_text().strip()\n",
    "#             data_points.append(point)\n",
    "#     week_of.append(week_date)\n",
    "#     rank_current_week.append(data_points[0])\n",
    "#     title.append(song_title)\n",
    "#     artist.append(data_points[1])\n",
    "#     rank_prior_week.append(data_points[2])\n",
    "#     peak_pos.append(data_points[3])\n",
    "#     weeks_on_chart.append(data_points[4])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad78010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chart_dict = {'week_of':week_of, 'rank_current_week':rank_current_week, 'title':title, 'artist':artist, 'rank_prior_week':rank_prior_week, 'peak_pos':peak_pos, 'weeks_on_chart':weeks_on_chart}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10fe385",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chart = pd.DataFrame(chart_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133bcd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chart.to_csv('../data/Billboard/test_chart.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98282d81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da06536e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
